{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from reader import samples_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This file contains a sample dataset that includes timestamp and pixel arrays.\n",
    "The pixel array has a dimension of (1145, 5, 5, 3),\n",
    "which represents (number of measurements, number of pixels in x axis,  number of pixels in y axis, rgb),\n",
    "with cells containing the r/g/b value.\n",
    "\n",
    "Files from SID OptiBP measurements can be downloaded from optibp-indo.appspot.com in Cloud Storage,\n",
    "Accessible from OptiBP-Indo project under sid-indonesia.org Google Cloud Platform.\n",
    "'''\n",
    "\n",
    "filename = r\"./sample.zip\"\n",
    "samples = samples_reader.read_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary with the timestamps\n",
    "valBin = {'t': samples.timestamps.tolist()}\n",
    "\n",
    "# Loop through each dimension of the pixel array: width (x), height (y), and color channels (r(c = 0) / g(c = 1) / b(c = 2)))\n",
    "for x in range(samples.pixels.shape[1]):\n",
    "    for y in range(samples.pixels.shape[2]):\n",
    "        for c in range(samples.pixels.shape[3]):\n",
    "            # Create a dictionary entry for the pixel values over time at a specific (x, y, c) location\n",
    "            val = {f'{x}_{y}_{c}': [samples.pixels[t, x, y, c] for t in range(samples.pixels.shape[0])]}\n",
    "            # Merge the new dictionary entry into the existing valBin dictionary\n",
    "            valBin = valBin | val\n",
    "\n",
    "# Convert the dictionary into a pandas DataFrame\n",
    "valBin = pd.DataFrame.from_dict(valBin)\n",
    "\n",
    "# Compute the difference between each row and the previous row, adding a prefix 'd_' to each column name\n",
    "difBin = valBin.diff().add_prefix('d_')\n",
    "\n",
    "# valBin.to_excel(r'waveform sample.xlsx')\n",
    "# difBin.to_excel(r'waveform sample delta.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe color represent the wavelength that is being detected by the red, blue and green sensors on the CMOS array of the camera.\\n\\nThe pixels are either 25 specifically selected pixels across the CMOS array, or more likely the averages of pixels in 25 ‘zones’,\\nfor each image frame captured by the camera each 0.033 second (i.e., 30 frames per second).\\nYour determination is correct that 0_0_0 means the pixel or area at x=0 and y=0 for the red CMOS channel.\\n\\nThe pixel sampling is being done because each finger placement may be a bit different, so the average signal across the image may be more reliable for the analysis.\\n\\nHemoglobin, which is the main molecule being detected by the camera as blood pulses through the finger, has a maximum absorption in the green and red ranges,\\nso those channels will tend to decrease when blood volume expands at the skin surface with each pulse (please see attached paper figure 1).\\nThere is likely not much useful information in the blue channel, and it is probably why the script plots 2_2_1 as that is one of the green channels.\\n\\nThe time, e.g., 7 seconds, to start assessing blood pressure is based on some stability in the images,\\nand so when there is some minimal delta across all 25 pixels or areas and for a certain amount of time,\\nthe image frames are then initiated into the real time algorithm for blood pressure.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explanation from OptiBp developer team\n",
    "\n",
    "'''\n",
    "The color represent the wavelength that is being detected by the red, blue and green sensors on the CMOS array of the camera.\n",
    "\n",
    "The pixels are either 25 specifically selected pixels across the CMOS array, or more likely the averages of pixels in 25 ‘zones’,\n",
    "for each image frame captured by the camera each 0.033 second (i.e., 30 frames per second).\n",
    "Your determination is correct that 0_0_0 means the pixel or area at x=0 and y=0 for the red CMOS channel.\n",
    "\n",
    "The pixel sampling is being done because each finger placement may be a bit different, so the average signal across the image may be more reliable for the analysis.\n",
    "\n",
    "Hemoglobin, which is the main molecule being detected by the camera as blood pulses through the finger, has a maximum absorption in the green and red ranges,\n",
    "so those channels will tend to decrease when blood volume expands at the skin surface with each pulse (please see attached paper figure 1).\n",
    "There is likely not much useful information in the blue channel, and it is probably why the script plots 2_2_1 as that is one of the green channels.\n",
    "\n",
    "The time, e.g., 7 seconds, to start assessing blood pressure is based on some stability in the images,\n",
    "and so when there is some minimal delta across all 25 pixels or areas and for a certain amount of time,\n",
    "the image frames are then initiated into the real time algorithm for blood pressure.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the rows from difBin where the corresponding timestamp in valBin is greater than or equal to samples.recording_start\n",
    "# Specifically, select the 'd_2_2_1' column and reset its index\n",
    "sampleSelect = difBin[valBin['t'] >= samples.recording_start]['d_2_2_1'].reset_index()\n",
    "\n",
    "# Create a Series that identifies peaks in the 'd_2_2_1' column\n",
    "# A peak is identified where the current value is greater than 0 and the next value is less than 0\n",
    "sampleIsPeak = pd.Series(\n",
    "    [(sampleSelect['d_2_2_1'][i] > 0) & (sampleSelect['d_2_2_1'][i + 1] < 0) for i in sampleSelect.index if i != sampleSelect.index.max()],\n",
    "    name='is_peak'\n",
    ")\n",
    "\n",
    "# Concatenate the is_peak Series to sampleSelect DataFrame along the columns\n",
    "sampleSelect = pd.concat([sampleSelect, sampleIsPeak], axis=1)\n",
    "\n",
    "# Find the timestamps in valBin corresponding to the indices where 'is_peak' is True\n",
    "# Subtract samples.recording_start to get the peak times relative to the start of recording\n",
    "samplePeaks = valBin['t'].loc[sampleSelect[sampleSelect['is_peak'] == True]['index'].to_list()] - samples.recording_start\n",
    "samplePeaks.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Calculate the differences between consecutive peaks and add a prefix 'd_' to the column names\n",
    "sampleDelta = samplePeaks.diff().to_frame().add_prefix('d_')\n",
    "\n",
    "# Concatenate the peak times and their differences into a single DataFrame\n",
    "samplePeaks = pd.concat([samplePeaks, sampleDelta], axis=1)\n",
    "\n",
    "# Calculate the upper and lower boundaries for classifying peak intervals\n",
    "# Upper boundary: mean of the peak differences + 1 standard deviation\n",
    "# Lower boundary: mean of the peak differences - 1 standard deviation\n",
    "upperBoundary = samplePeaks['d_t'].mean() + 1 * samplePeaks['d_t'].std()\n",
    "lowerBoundary = samplePeaks['d_t'].mean() - 1 * samplePeaks['d_t'].std()\n",
    "\n",
    "# Classify each peak interval as 'over', 'under', or 'within' based on the boundaries\n",
    "samplePeaks['d_t_class'] = np.where(samplePeaks['d_t'] > upperBoundary, 'over', \n",
    "                                    np.where(samplePeaks['d_t'] < lowerBoundary, 'under', 'within'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGGIFGGIFGGGIFGIFIDFGIFIFHACGIFGHACIFG\n"
     ]
    }
   ],
   "source": [
    "# See the attached image for the definitions of each letter class\n",
    "\n",
    "# Initialize an empty list to store the classifications\n",
    "pikBin = []\n",
    "\n",
    "# Iterate over the indices of samplePeaks DataFrame\n",
    "for i in samplePeaks.index:\n",
    "    if i != samplePeaks.index.min() and i != samplePeaks.index.max():\n",
    "        # Check the current and next classification and append corresponding letter to pikBin\n",
    "        if samplePeaks['d_t_class'][i] == 'over' and samplePeaks['d_t_class'][i + 1] == 'over':\n",
    "            pikBin.append('A')\n",
    "        elif samplePeaks['d_t_class'][i] == 'over' and samplePeaks['d_t_class'][i + 1] == 'under':\n",
    "            pikBin.append('B')\n",
    "        elif samplePeaks['d_t_class'][i] == 'over' and samplePeaks['d_t_class'][i + 1] == 'within':\n",
    "            pikBin.append('C')\n",
    "        elif samplePeaks['d_t_class'][i] == 'under' and samplePeaks['d_t_class'][i + 1] == 'under':\n",
    "            pikBin.append('D')\n",
    "        elif samplePeaks['d_t_class'][i] == 'under' and samplePeaks['d_t_class'][i + 1] == 'over':\n",
    "            pikBin.append('E')\n",
    "        elif samplePeaks['d_t_class'][i] == 'under' and samplePeaks['d_t_class'][i + 1] == 'within':\n",
    "            pikBin.append('F')\n",
    "        elif samplePeaks['d_t_class'][i] == 'within' and samplePeaks['d_t_class'][i + 1] == 'within':\n",
    "            pikBin.append('G')\n",
    "        elif samplePeaks['d_t_class'][i] == 'within' and samplePeaks['d_t_class'][i + 1] == 'over':\n",
    "            pikBin.append('H')\n",
    "        elif samplePeaks['d_t_class'][i] == 'within' and samplePeaks['d_t_class'][i + 1] == 'under':\n",
    "            pikBin.append('I')\n",
    "    else:\n",
    "        # Append 'not used' for the first and last index\n",
    "        pikBin.append('not used')\n",
    "\n",
    "# Add the classification to the samplePeaks DataFrame\n",
    "samplePeaks['peak_class'] = pikBin\n",
    "\n",
    "# Concatenate the classifications into a single string, excluding 'not used'\n",
    "pikStr = ''.join([l for l in pikBin if l != 'not used'])\n",
    "\n",
    "print(pikStr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SID_Najmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
